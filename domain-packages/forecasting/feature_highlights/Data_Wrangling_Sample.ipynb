{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling with \"Azure ML Package for Forecasting\"\n",
    "\n",
    "## Summary\n",
    " This notebook demonstrates how to use the primary data structure - `TimeSeriesDataFrame` that comes with `Azure Machine Learning Package for Forecasting`(AMLPF). The `TimeSeriesDataFrame` is at the core of the package and it subclasses the [Pandas dataframe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). In this notebook, we will demonstrate some common data wrangling tasks that involve the `TimeSeriesDataFrame` on the [U. Chicago Dominick's Finer Foods dataset](https://research.chicagobooth.edu/kilts/marketing-databases/dominicks). \n",
    " \n",
    " The following data wrangling tasks are shown:\n",
    " * Loading datasets\n",
    " * Working with Date strings\n",
    " * Creating TimeSeriesDataFrame\n",
    " * Changing shape of TimeSeriesDataFrame\n",
    " * Slicers with TimeSeriesDataFrame\n",
    " * Aggregation operations with TimeSeriesDataFrame\n",
    " * Merge operations with TimeSeriesDataFrame\n",
    " \n",
    "**Please refer to our [programming guide](https://azuremlftkrelease.blob.core.windows.net/docsdev/html/index.html) for a full list of transfomers and models available in AMLPF and try them out.**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pkg_resources\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from ftk import TimeSeriesDataFrame\n",
    "from ftk.data import get_a_year_of_daily_weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Explore\n",
    "\n",
    "Any [IO tools](https://pandas.pydata.org/pandas-docs/stable/io.html) supported by Pandas can be used to load data. One of the most common ways to do so is the `read_csv` API since many datasets are distributed in that format.\n",
    "In addittion to wide variety of formats, Pandas provides many ways to handle large datasets. One of the most common ways to handle is by loading them in chunks. Columnar/vector representation of datasets can be compressed to a greater degree that relational frames and are another good option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data from CSV\n",
    "csv_path = pkg_resources.resource_filename('ftk', 'data/dominicks_oj/dominicks_oj.csv')\n",
    "whole_df = pd.read_csv(csv_path, low_memory = False)\n",
    "whole_df.head()\n",
    "\n",
    "# Read large datasets in chunks\n",
    "chunk_size = 500\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(csv_path, chunksize=chunk_size):    \n",
    "    chunks.append(chunk)\n",
    "whole_df_chunked = pd.concat(chunks, axis=0)\n",
    "whole_df_chunked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Date strings\n",
    "\n",
    "Pandas dataframe offers extensive support to working with time-series and thus Date objects in general. A common\n",
    "requirement is to convert datetime strings to DateTime objects. Pandas has datetime objects that model them as a single\n",
    "point in time via the `Timestamp` or a as a time range/period - `Period`. In `TimeSeriesDataFrame` we assume the Date index to be of `Timestamp` type and hence the time axis is of type `DateTimeIndex`. This column is part of the multi-index and stored in the `time_colname` metadata property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sales are contained in the 'logmove' column. \n",
    "# Values are logarithmic, so exponentiate and round them to get quantity sold\n",
    "def expround(x):\n",
    "    return math.floor(math.exp(x) + 0.5)\n",
    "whole_df['quantity'] = whole_df['logmove'].apply(expround)\n",
    "\n",
    "# Create `TimeStamp` using `to_datetime` passing in a string value \n",
    "weekZeroStart = pd.to_datetime('1989-09-07 00:00:00')\n",
    "print(weekZeroStart)\n",
    "\n",
    "# Create `TimeStamp` passing in a string value \n",
    "weekZeroStartTS = pd.Timestamp('1989-09-07 00:00:00')\n",
    "print(weekZeroStartTS)\n",
    "\n",
    "# Create `TimeStamp` with a specific format. The `to_datetime` supports\n",
    "# formatters.\n",
    "weekZeroStartFMT = pd.to_datetime('1989-09-07 00:00:00', format='%Y/%m/%d')\n",
    "print(weekZeroStartFMT)\n",
    "\n",
    "weekZeroEnd = pd.to_datetime('1989-09-13 23:59:59')\n",
    "whole_df['WeekFirstDay'] = whole_df['week'].apply(lambda n: weekZeroStart + timedelta(weeks=n))\n",
    "whole_df['WeekLastDay'] = whole_df['week'].apply(lambda n: weekZeroEnd + timedelta(weeks=n))\n",
    "whole_df[['store','brand','WeekLastDay', 'quantity']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TimeSeriesDataframe\n",
    "\n",
    "In this section below, we create a `TimeSeriesDataFrame` from a Pandas dataframe. In the TimeSeriesDataFrame representation, the time axis and grain are part of the data frame index - which is a composite or a MultiIndex in Pandas. This allows easy access to Pandas datetime slicing capabilities.\n",
    "\n",
    "A MultiIndex is a multi-level or hierarchical representation for Pandas objects. Such an index indicates\n",
    "the usage of two or more columns to uniquely differentiate or locate records. In database terms, MultiIndex is simply\n",
    "a [compound](https://en.wikipedia.org/wiki/Compound_key) or composite key as used in database parlance.\n",
    "\n",
    "You can also glean common information about the `TimeSeriesDataFrame` by using Pandas' APIs.\n",
    "Some of the common statistics involve finding the shape of the dataframe, the columns and their\n",
    "datatypes, the indexes and information about the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TimeSeriesDataFrame\n",
    "# Use end of period as the time index\n",
    "# Store and brand combinations label the grain \n",
    "# i.e. there is one time series for each unique pair of store and grain\n",
    "whole_tsdf = TimeSeriesDataFrame(whole_df, \n",
    "                                 grain_colnames = ['store', 'brand'],\n",
    "                                 time_colname = 'WeekLastDay', \n",
    "                                 ts_value_colname = 'quantity',\n",
    "                                 group_colnames = 'store')\n",
    "\n",
    "# TimeSeriesDataFrame info\n",
    "print(whole_tsdf.info())\n",
    "\n",
    "# Find info about the shape of the TimeSeriesDataframe\n",
    "print(whole_tsdf.shape)\n",
    "\n",
    "# Describe TimeSeriesDataframe\n",
    "print(whole_tsdf.describe())\n",
    "\n",
    "# Index names\n",
    "print(whole_tsdf.index.names)\n",
    "\n",
    "# Vector of unique values for specific index column\n",
    "print(whole_tsdf.index.get_level_values('brand').unique())\n",
    "\n",
    "# Print sample rows in the data frame from the top.\n",
    "# Includes the default grain and time axis columns) other than\n",
    "# the ones explicitly specified.\n",
    "whole_tsdf[['quantity', 'price']].head()\n",
    "\n",
    "# The ```TimeSeriesDataFrame.ts_report()``` function generates a comprehensive\n",
    "# report of the time series data frame, including both general data \n",
    "# description and statistics specific to time series data. \n",
    "%matplotlib inline\n",
    "whole_tsdf.ts_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing shape of TimeSeriesDataFrame\n",
    "\n",
    "There are several ways to add or remove columns and rows in a `TimeSeriesDataFrame`. \n",
    "In the section below, we will look at some of the most common ways to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with default value 'NewColumn'\n",
    "whole_tsdf['defaultcol'] = 'Default'\n",
    "\n",
    "# Add a new composed column using values from other columns\n",
    "# \"Purchase impact\" - ratio of income to per unit cost of item\n",
    "whole_tsdf['purchimpact'] = whole_tsdf['INCOME']/whole_tsdf['price']\n",
    "\n",
    "# Add a new column with conditional logic\n",
    "whole_tsdf['isprofitable'] = np.where(whole_tsdf['price']>=2.0, True, False)\n",
    "\n",
    "# Add a new column using Python lambda functions\n",
    "def calc_tax(price):\n",
    "    return price * 0.1\n",
    "whole_tsdf['taxamount'] = whole_tsdf.price.apply(calc_tax)\n",
    "\n",
    "# Remove columns by using Drop\n",
    "whole_tsdf = whole_tsdf.drop(['defaultcol', 'isprofitable'], axis=1)\n",
    "whole_tsdf.tail()\n",
    "\n",
    "# Remove columns by selecting a subset of columns\n",
    "whole_tsdf_subset = whole_tsdf[['price', 'quantity']]\n",
    "whole_tsdf_subset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicers with TimeSeriesDataFrame\n",
    "\n",
    "Pandas has powerful capabilities to slice dataframe. `TimeSeriesDataFrame` fully supports all of these operations\n",
    "that are allowed on the native dataframes. Pandas offer the powerful `loc` API to slice objects using labels, but\n",
    "because `TimeSeriesDataFrame` is multi indexed, the `IndexSlice` or the `slice` APIs can be used in conjunction to perform all sorts of data mangling.\n",
    "\n",
    "**NOTE:** \n",
    "* Since there are multiple indexes in TimeSeriesDataFrame, any slice operation must specify the slice criterion for each index. \n",
    "* The indexes are ordinal with the `time_colname` being first and the `grain_colnames` columns in the order they were passed in during the creation.\n",
    "* The \":\" called the null slicer indicates no slicing on the specified index. Not specifying any index simply defaults to a null slice for that ordinal index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe must be sorted before slice\n",
    "whole_tsdf.sort_index(inplace=True)\n",
    "\n",
    "# Slice on a range of values with tuples. Our current TimeSeriesDataFrame\n",
    "# object has the 'WeekLastDay' time column and two grain columns - 'store' and\n",
    "# 'brand'. The slicing operations will this specify slice criterion for each of these \n",
    "# index columns in that order.\n",
    "whole_tsdf_singleweek_store5 = whole_tsdf.loc[('1990-06-20 23:59:59', 5,), :]\n",
    "whole_tsdf_singleweek_store5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sales of tropicana in store 5 during summer 1990 \n",
    "whole_tsdf_tropicana_store5_summer90 = whole_tsdf.loc[pd.IndexSlice['1990-06':'1990-09', 5, 'tropicana'], :]\n",
    "whole_tsdf_tropicana_store5_summer90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sales of store 5 during summer 1990 \n",
    "whole_tsdf_store5_summer90 = whole_tsdf.loc[pd.IndexSlice['1990-06':'1990-09', 5], :]\n",
    "whole_tsdf_store5_summer90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sales during summer 1990 across all stores\n",
    "whole_tsdf_summer90 = whole_tsdf.loc[pd.IndexSlice['1990-06':'1990-09',], :]\n",
    "whole_tsdf_summer90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the sales for all time periods for a specific brand at a specific store.\n",
    "# Note the use of axis=0 indicating that the slicing is row level.\n",
    "# In this case we want rows across all date index for 5 for 'minute.maid' brand.\n",
    "whole_tsdf_mm = whole_tsdf.loc(axis=0)[:, 5, ['minute.maid']]\n",
    "whole_tsdf_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation with TimeSeriesDataFrame\n",
    "\n",
    "`TimeSeriesDataFrame` supports several aggregation facilities including Pandas' `groupby` API. \n",
    "In addition, there are several APIs to slice by well-known index metadata fields that `TimeSeriesDataFrame`\n",
    "offers to stratify time series data. We will show how some of these can be applied in this section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group TimeSeriesDataFrame by any available columns\n",
    "# Uses native Pandas' groupby\n",
    "tsdf_groupby = whole_tsdf.groupby(['store', 'brand'])\n",
    "tsdf_groupby.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add revenue column to TimeSeriesDataFrame.\n",
    "whole_tsdf['revenue'] = whole_tsdf.price * whole_tsdf.quantity\n",
    "\n",
    "# Compute total sales in store across entire date range\n",
    "whole_tsdf.groupby_grain()[['revenue']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sales in a store across all available time ranges\n",
    "# The 'store' is our time-series group column as indicated by the 'group_colnames'.\n",
    "# We can thus slice the data frame using the groupby_group API in AMLPF.\n",
    "whole_tsdf_groupby_group = whole_tsdf.groupby_group()[['revenue']]\n",
    "whole_tsdf_groupby_group.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group TimeSeriesDataFrame by grain columns - 'store' and 'brand'\n",
    "# Uses AMPPF's `groupby_grain` API.\n",
    "tsdf_groupby_grain = whole_tsdf.groupby_grain()\n",
    "tsdf_groupby_grain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Computing total sales in a store in a given month of a year\n",
    "#\n",
    "import calendar    \n",
    "year = '1990'\n",
    "month = '08'\n",
    "store_val = 2\n",
    "new_colname = 'yearmonth'  \n",
    "year_month = str(year) + str(month)\n",
    "# Clone TimeSeriesDataFrame\n",
    "df_tmp = whole_tsdf.copy()\n",
    "\n",
    "# Create a new column and assign the Date index column value\n",
    "df_tmp = df_tmp.assign(yearmonth=lambda x: \\\n",
    "                       df_tmp.index.get_level_values(0))\n",
    "\n",
    "# Re-format the datetime value to yearmonth\n",
    "df_tmp[new_colname] = df_tmp[new_colname].apply(lambda z: z.strftime('%Y%m'))\n",
    "\n",
    "# Group by the store and year-month and compute sum of TotalSales\n",
    "# The slice the dataframe for the specific store and yearmonth value\n",
    "df_tmp = df_tmp.groupby(['store',new_colname]).agg({'revenue': np.sum})\\\n",
    "                .loc[pd.IndexSlice[store_val, year_month], :]\n",
    "print('Total revenue for store {} in {} {} is {}'\\\n",
    "      .format(store_val, calendar.month_abbr[int('08')], year, df_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge operations with TimeSeriesDataFrame\n",
    "\n",
    "`TimeSeriesDataFrame` offers good support for merging and concatenating dataframes. In the section below, we \n",
    "show how weather information from the [NOAA's GSOD dataset](https://www7.ncdc.noaa.gov/CDO/GSOD_DESC.txt) can be merged with our `TimeSeriesDataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weather data\n",
    "weather_1990 = get_a_year_of_daily_weather_data(year=1990)\n",
    "weather_1991 = get_a_year_of_daily_weather_data(year=1991)\n",
    "weather_1992 = get_a_year_of_daily_weather_data(year=1992)\n",
    "\n",
    "# Preprocess weather data\n",
    "weather_all = pd.concat([weather_1990, weather_1991, weather_1992])\n",
    "weather_all.reset_index(inplace=True)\n",
    "\n",
    "# Only use a subset of columns\n",
    "weather_all = weather_all[['TEMP', 'DEWP', 'WDSP', 'PRCP']]\n",
    "\n",
    "# Compute the WeekLastDay column, in order to merge with sales data\n",
    "weekZeroStart = pd.to_datetime('1989-09-07 00:00:00')\n",
    "weekZeroEnd = pd.to_datetime('1989-09-13 23:59:59')\n",
    "weather_all['WeekLastDay'] = pd.Series(\n",
    "    (weather_all.index.get_level_values('YEARMODA') - weekZeroStart), \n",
    "    index=weather_all.index.get_level_values('YEARMODA')).apply(lambda n: weekZeroEnd \n",
    "                                                                + timedelta(weeks=math.floor(n.days/7)))\n",
    "weather_all = weather_all.groupby('WeekLastDay').mean()\n",
    "weather_all = TimeSeriesDataFrame(weather_all, time_colname='WeekLastDay')\n",
    "\n",
    "# Merge weather data with sales data\n",
    "whole_tsdf = whole_tsdf.merge(weather_all, how='left', on='WeekLastDay')\n",
    "whole_tsdf.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
